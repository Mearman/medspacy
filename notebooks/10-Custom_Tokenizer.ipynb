{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import medspacy\n",
    "\n",
    "from medspacy.custom_tokenizer import create_medspacy_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "Example of how to enable the default medspaCy tokenizer and compare it to the default English tokenizer on \n",
    "some representative examples from short clinical text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can only use one of the following tokenizers, so let's use the medspacy tokenizer \n",
    "# which handles infixes (e.g. 'h/o', 'chf+cp', etc)\n",
    "\n",
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokenizer = nlp.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "medspacy_tokenizer = create_medspacy_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process our document with both default and medspacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = r'Pt c\\o n;v;d h\\o chf+cp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_doc = spacy_tokenizer(example_text)\n",
    "\n",
    "medspacy_doc = medspacy_tokenizer(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the result, we can see that the medspaCy tokenizer is much more aggressive on punctuation. This is intentional and has better handling of long sequences of punctuation, typos involving punctuation, and compound words joined with punctuation.\n",
    "\n",
    "The medspacy tokenizer is not always appropriate for a task, but can often make pattern matching with rules simpler and more accurate. Please test both the default tokenizer, medspaCy tokenizer, and other options for any particular project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens in default tokenizer\n",
      "Pt\n",
      "c\\o\n",
      "n;v;d\n",
      "h\\o\n",
      "chf+cp\n"
     ]
    }
   ],
   "source": [
    "print('Tokens in default tokenizer')\n",
    "for token in default_doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens in medspacy tokenizer\n",
      "Pt\n",
      "c\n",
      "\\\n",
      "o\n",
      "n\n",
      ";\n",
      "v\n",
      ";\n",
      "d\n",
      "h\n",
      "\\\n",
      "o\n",
      "chf\n",
      "+\n",
      "cp\n"
     ]
    }
   ],
   "source": [
    "print('Tokens in medspacy tokenizer')\n",
    "for token in medspacy_doc:\n",
    "    print(token.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
